model = Context
name = emr_autoscale_ctx
data {
  launchData {
    type = "aws-emr",
    launcherSettingsName = "default_emr"
    releaseLabel = "emr-5.17.0"
    instances = [
      {
         instanceGroupType = "master"
         instanceType = "m4.large"
         name = "my-master"
         instanceCount = 1
         market = "onDemand"
      },
      {
         instanceGroupType = "core"
         instanceType = "m4.large"
         name = "my-core"
         instanceCount = 2
         market = "spot"
         bidPrice = "0.035"
         autoScaling {
           min = 2
           max = 5
           rules = [
             {
               name = "Default-scale-out"
               description = "Replicates the default scale-out rule in the console for YARN memory."
               adjustmentType = "changeInCapacity"
               scalingAdjustment = 1
               coolDown = 300
               trigger {
                 comparisonOperator = "lessThan"
                 evaluationPeriods= 1
                 metricName = "YARNMemoryAvailablePercentage"
                 namespace = "AWS/ElasticMapReduce"
                 period = 300
                 threshold = 15
                 statistic = "average"
                 unit = "PERCENT"
                 dimensions = [ { "key" : "JobFlowId", "value" : "${emr.clusterId}" } ]
               }
             }
           ]
         }
      }
    ]
  }
  maxJobs = 1
  maxConnFailures = 1
  workerMode = "exclusive"
  precreated = false
  sparkConf {
    spark.executor.instances = 2
    spark.submit.deployMode = "cluster"
    spark.master = "yarn"
    spark.executor.memory = "1G"
    spark.executor.cores = 2
  }
  downtime = "1200s"
  streamingDuration = "1s"
}
